
## Week of 11/02/23 (Week11) ##


### Reflections ### 
-In this assignment, I have been plunged into the world of Large Language Models (LLMs) for the first time, alongside ZeroWidth.

This area piqued my interest particularly because it was an opportunity to try my hand at the recently popular field of Prompt Engineering. During my time in graduate school, I was one of the heavy users of ChatGPT, and as I learned in lectures, maintaining consistency in the prompts was challenging, so I often ended up asking random questions.

While crafting my resume, I became curious about what my own writing style could be, and I was disappointed by the overtly 'translated' feel to the language. Therefore, I decided to set up a cute and fun LLM that would be suitable for me.

I wrote down information about myself and created a mix of Korean/English language usage, and I integrated emojis to develop a bot that could generate information about me.

When I adjusted using the Similarity Threshold, I noticed more diverse results. It was interesting to see that a higher temperature indeed leads to the use of words and phrases that are less predictable.

### Speculations ###
- I want to fine-tune the details further, and now I'm interested in doing the fine-tuning myself, rather than using this program. I feel there might be limitations to just using the program, as it seems to produce results that are too similar to the styles seen in the existing GPT models.


### Conclusion ###
- Of course, it was an experience that didn't involve any coding on my part, but it was very meaningful for me, and it seems to have alleviated some of the frustration I always felt when using ChatGPT. The fact that I can change not only the Knowledge but also the Instructions is interesting.
